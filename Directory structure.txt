# Directory structure: # price_monitor/ # +-- main.py # +-- scraper.py # +-- notifier.py # +-- summarizer.py # +-- plugins/ # ¦ +-- shwapno.py # +-- requirements.txt # requirements.txt # aiohttp # beautifulsoup4 # playwright # openai # pyttsx3 # APScheduler # pydantic def main_py(): content = ''' import asyncio from fastapi import FastAPI, HTTPException from apscheduler.schedulers.asyncio import AsyncIOScheduler from pydantic import BaseModel, AnyHttpUrl from scraper import PriceScraper from notifier import Notifier from summarizer import Summarizer from plugins import load_plugins app = FastAPI() scheduler = AsyncIOScheduler() plugins = load_plugins('plugins') class TrackRequest(BaseModel): url: AnyHttpUrl threshold: float = None @app.on_event("startup") async def startup(): scheduler.start() @app.post("/track") def add_tracker(req: TrackRequest): job_id = f"track_{req.url}".replace('://','_') scheduler.add_job( monitor_task, 'interval', args=[req.url, req.threshold], seconds=300, id=job_id, replace_existing=True ) return {"job_id": job_id} async def monitor_task(url: str, threshold: float): try: # select plugin based on domain for plugin in plugins: if plugin.domain in url: price = await plugin.fetch_price(url) break else: price = await PriceScraper().fetch(url) # summarization and prediction summary = await Summarizer().summarize_trend(url) if threshold and price <= threshold: await Notifier().notify_price_drop(url, price, summary) except Exception as e: await Notifier().notify_error(url, str(e)) @app.get("/health") def health(): return {"status": "ok"} # to run: uvicorn main:app --reload ''' return content print(main_py()) check all fix all .,,,Price Tracking Tools for Bangladeshi E-Grocery Platforms The table below summarizes a range of price/stock monitoring tools and scripts (open-source or free) that can be adapted to Bangladeshi online supermarkets (Meena Bazar, Shwapno, Chaldal, etc.). It includes CLI scripts, self-hosted web apps, SaaS/extension tools, and browser extensions. Key features, scraping approaches, scheduling, and notification methods are noted. Tool Type / Platform Key Features & Mechanisms Open-Source Link / Docs PageProbe Browser Extension (Chrome/FF) Local extension; unlimited trackers with advanced conditions (regex, arithmetic); configurable cron-style checks; notifications via desktop, audio, HTTP POST, IFTTT, Discord/Slack/Telegram; supports dynamic pages (Live Content mode), JSON, CSS/XPath/JSONPath selectors nodetics.com . Fully local (no account needed) and free nodetics.com . nodetics/PageProbe Distill.io Browser Extension / SaaS Cloud-based monitor; Chrome/Firefox extension; select page elements via UI; custom check frequency; smart conditions (contains text, regex, etc); 24/7 monitoring; version history; password-protected/PDF page support; instant alerts via email/SMS/push/apps distill.io . Free tier available. distill.io changedetection.io Self-hosted Web App (Python) Monitors pages for content changes; special "Restock & Price" mode extracts product price/stock metadata github.com ; can switch between fast non-JS fetch and full Chrome/Playwright JS fetch for dynamic sites github.com ; supports element filtering (CSS/XPath selectors, regex) github.com ; schedule interval configurable; visual diff-by-word/line when changes occur github.com ; notifications via Email/Telegram/Slack/Discord/Webhook/etc.; optional screenshot on change github.com . Can handle logins or search flows via "browser steps". dgtlmoon/changedetection.io PriceBuddy Self-hosted Web App (Laravel) Multi-store grocery price tracker; users can add products with multiple URLs; daily price fetch via cron; stores history with chart visualizations github.com ; extractors via CSS selector, regex or JSONPath; supports JS-heavy sites via a headless "Scrapper" component github.com ; multi-user accounts; in-app/push/email notifications on price-match or drop; tagging/organization of products; simple Docker deployment with built-in cron job github.com . (Uses Laravel/PHP backend with Vue/Filament UI.) jez500/pricebuddy Discount Bandit Self-hosted Web App (Laravel) Price tracker across multiple e-commerce stores; supports adding desired price thresholds; built-in Laravel artisan commands for setup and updates; background tasks via cron (or artisan CLI) github.com ; notifications via ntfy.sh (mobile push) and Telegram github.com ; can run with SQLite or MySQL; Docker image available github.com . (Modern Laravel/PHP app.) Cybrarist/Discount-Bandit Automated Price Tracking (Streamlit) Self-hosted Web App (Python) Web interface (Streamlit) to manage tracked products; fetches from various e-commerce sites (via Firecrawl API); stores price history (SQLite/Postgres) and plots trends; Discord webhook alerts when price drops below threshold github.com ; scheduled checks (GitHub Actions or cron) configurable (hourly/daily/weekly) github.com ; secure storage (SQLAlchemy ORM); comprehensive testing with pytest github.com . (Requires a Firecrawl API key for scraping.) BexTuychiev/automated-price-tracking Price-Tracker (kanha638) Self-hosted Web App Web UI (Flask/Express/React) for users to enter product URLs; scrapes current price from specified shopping sites; stores data in DB; sends email or in-app notifications on price drop/offers github.com ; user-friendly interface; built for multi-site support; likely static scraping (BeautifulSoup) and scheduled jobs (cron). kanha638/Price-Tracker duyet/pricetrack (Tracker.duyet.net) Serverless Web App (Firebase) Firebase-based system (Cloud Functions + Firestore + Cloud Scheduler); supports major ecommerce APIs (tiki.vn, shopee, etc.) github.com ; users add product URLs via web; scheduled Firebase Cron triggers invoke functions to pull current price/availability; stores history in Firestore; email alerts when price drops github.com ; admin panel and public UI on Firebase Hosting. duyet/pricetrack pyscraper (Esshahn) CLI Python Script Simple script using requests+BeautifulSoup to scrape static product pages (Amazon, etc.); reads a JSON of product URLs and desired prices; on each run compares current price to target, sends email alert if at/below threshold github.com ; intended to run via cron (instructions given). Minimal dependencies. Esshahn/pyscraper Ecommerce-Price-Tracker (shravanasati) CLI Python Script Python utility to track Amazon and Flipkart product prices; takes product name/URL and desired price; scrapes pages (requests/bs4/Helium); sends email alert when price drops below target github.com ; can track across both sites simultaneously; configure via JSON credentials file; run periodically (e.g. cron). shravanasati/Ecommerce-Price-Tracker Key Notes on Mechanisms and Patterns: Scraping Strategies: Lightweight scripts (like pyscraper or Ecommerce-Price-Tracker) use static HTML requests and parse with BeautifulSoup (suitable for simple pages). Modern tools support hybrid scraping: e.g. changedetection.io can use a fast non-JS fetch or a headless Chrome (Playwright/WebDriver) to handle JS-heavy pages github.com ; PriceBuddy uses a specialized "Scrapper" module for SPAs github.com ; PageProbe offers a "Live Content" mode for dynamic pages nodetics.com . Fallbacks often include using headless browsers or third-party APIs/proxies. Scheduling/Jobs: Scripts typically rely on OS cron (or GitHub Actions) for regular polling. Web apps embed scheduling in different ways: PriceBuddy and Discount Bandit run cron jobs inside Docker or via system cron github.com ; duyet/pricetrack uses Firebase Cloud Scheduler (cron triggers) to invoke functions github.com ; changedetection.io lets the user set check intervals in the UI; Automated-Price-Tracking suggests GitHub Actions for periodic runs. Some systems use job queues (e.g. Laravel's queue/jobs or Firebase Pub/Sub), though specifics may vary by implementation. Change Detection & Diffing: Most tools store the last-seen price and compare on each run. Simpler scripts alert only on threshold breaches. Advanced monitors show diffs: changedetection.io highlights textual changes by word/line github.com and even shows contextual diffs. PriceBuddy visualizes historical price graphs. PageProbe logs values over time (charting supported). These allow users to see trends or unexpected changes. Notifications: All tools support some alerts. Common channels include Email, which all the CLI scripts and many apps use. Many systems also support push/webhook notifications: changedetection.io (Slack, Discord, Telegram, SMS, etc.), PriceBuddy (in-app, email, or push via Gotify/Pushover), Discount Bandit (ntfy.sh and Telegram) github.com , duyet/pricetrack (email), PageProbe (desktop notifications, audio, HTTP POST to APIs) nodetics.com , and Distill.io (email, SMS, mobile app). Error Handling/Backoff: While not always explicitly documented, robust scrapers implement retries and backoff for network or anti-bot issues. For example, using proxies or rate-limiting (Bright Data support is noted for changedetection.io). Tools like duyet/pricetrack rely on Firebase infrastructure for retry logic, while custom scripts may employ exponential backoff in code. Patterns like circuit breakers (to stop repeated failures) and observer/pub-sub (for decoupling events) can be applied when extending these tools, though details depend on the codebase. Code Architecture: These projects use various designs. Web apps (PriceBuddy, Discount Bandit, Price-Tracker, Pricebook) use MVC frameworks (Laravel/PHP or Node/React) with separation of concerns (scraper modules vs notification modules). For instance, PriceBuddy uses Laravel/Filament (with PHPUnit tests and static analysis via PHPStan) and likely queues for background jobs github.com . duyet/pricetrack employs serverless functions (each URL tracking as a function) with Firebase Pub/Sub scheduling (so it's event-driven). Automated-Price-Tracking uses a Streamlit frontend + a Python backend, with SQLAlchemy (Postgres/SQLite) and pytest tests github.com . CLI scripts are single-process but can be containerized. Testability & Performance: Several projects include test suites (e.g. Automated-Price-Tracking uses pytest github.com ; PriceBuddy has a /tests directory and CI workflows). They often use Docker for consistent environments. Performance considerations involve avoiding overloading the sites: e.g. rate limits and scheduling intervals. Lightweight tools (shell or Python scripts) are very fast but limited, whereas headless-browser fetchers are slower but handle JS. References: Each tool's features are documented in its repo or website, e.g. the changedetection.io README github.com github.com and PriceBuddy docs github.com github.com above. The citations link to the original source lines for verification. Suggested Custom Enhancements To make a Cursor-integrated price tracker stand out for Bangladeshi markets, consider features like: Local Language Support: User interface and notifications in Bengali (Bangla) and English, to better serve local users. For example, translate alerts or even scrape site text in Bengali correctly. AI Trend Summarization: Apply AI to analyze collected price history and produce human-readable summaries (e.g. "Rice flour (Aata) prices on Shwapno have been stable around ?50 for 3 months, last dropping 10% during last Eid github.compython # price_monitor/main.py import asyncio from fastapi import FastAPI, HTTPException from apscheduler.schedulers.asyncio import AsyncIOScheduler from pydantic import BaseModel, AnyHttpUrl from typing import Optional, Dict, List from scraper import PriceScraper from notifier import Notifier from summarizer import Summarizer from plugins import load_plugins from models import PriceHistory, Product from database import init_db, get_session from datetime import datetime app = FastAPI(title="Bangladesh Grocery Price Tracker") scheduler = AsyncIOScheduler() plugins = load_plugins('plugins') notifier = Notifier() summarizer = Summarizer() class TrackRequest(BaseModel): url: AnyHttpUrl threshold: Optional[float] = None product_name: Optional[str] = None language: str = "en" # 'en' or 'bn' notification_prefs: Dict[str, bool] = { "email": True, "sms": False, "voice": False, "push": True } class BundleRequest(BaseModel): items: List[TrackRequest] name: str total_threshold: Optional[float] = None @app.on_event("startup") async def startup(): await init_db() scheduler.start() # Load any persisted tracking jobs from DB await restore_tracking_jobs() @app.post("/track") async def add_tracker(req: TrackRequest): session = get_session() try: product = session.query(Product).filter_by(url=str(req.url)).first() if not product: product = Product( url=str(req.url), name=req.product_name or await identify_product_name(req.url), threshold=req.threshold, language=req.language, notification_prefs=req.notification_prefs ) session.add(product) session.commit() job_id = f"track_{req.url}".replace('://','_') scheduler.add_job( monitor_task, 'interval', args=[req.url, req.threshold, req.language, req.notification_prefs], seconds=300, id=job_id, replace_existing=True ) return {"job_id": job_id, "product_id": product.id} finally: session.close() @app.post("/track/bundle") async def add_bundle_tracker(req: BundleRequest): job_ids = [] for item in req.items: track_resp = await add_tracker(item) job_ids.append(track_resp["job_id"]) # Add bundle monitoring job bundle_job_id = f"bundle_{req.name}".lower().replace(' ', '_') scheduler.add_job( monitor_bundle_task, 'interval', args=[req.items, req.total_threshold], seconds=3600, id=bundle_job_id, replace_existing=True ) return {"bundle_job_id": bundle_job_id, "item_job_ids": job_ids} async def monitor_task(url: str, threshold: Optional[float], language: str, notification_prefs: Dict): session = get_session() try: product = session.query(Product).filter_by(url=url).first() if not product: return # Select plugin based on domain plugin = None for p in plugins: if p.domain in url: plugin = p break scraper = PriceScraper(plugin=plugin) price, stock_status = await scraper.fetch_price_and_stock(url) # Save price history history = PriceHistory( product_id=product.id, price=price, stock_status=stock_status, timestamp=datetime.utcnow() ) session.add(history) session.commit() # Get AI summary of trends summary = await summarizer.summarize_trend(product.id, language) # Check threshold and notify if threshold and price <= threshold: await notifier.notify_price_drop( product=product, current_price=price, summary=summary, notification_prefs=notification_prefs ) # Predict future prices prediction = await summarizer.predict_future_price(product.id) if prediction and prediction.get('likely_drop_soon'): await notifier.notify_prediction( product=product, prediction=prediction, notification_prefs=notification_prefs ) except Exception as e: await notifier.notify_error(url, str(e), language) finally: session.close() async def monitor_bundle_task(items: List[TrackRequest], total_threshold: Optional[float]): session = get_session() try: total_price = 0 bundle_status = {} for item in items: plugin = None for p in plugins: if p.domain in item.url: plugin = p break scraper = PriceScraper(plugin=plugin) price, stock = await scraper.fetch_price_and_stock(item.url) total_price += price bundle_status[item.url] = { "price": price, "stock": stock, "threshold": item.threshold } if total_threshold and total_price <= total_threshold: await notifier.notify_bundle_drop(items, bundle_status, total_price) except Exception as e: await notifier.notify_error("bundle", str(e), "en") finally: session.close() async def restore_tracking_jobs(): session = get_session() try: products = session.query(Product).all() for product in products: job_id = f"track_{product.url}".replace('://','_') scheduler.add_job( monitor_task, 'interval', args=[product.url, product.threshold, product.language, product.notification_prefs], seconds=300, id=job_id ) finally: session.close() async def identify_product_name(url: str) -> str: """Extract product name from URL or page content""" # Implementation would use scraping or plugin-specific logic return "Unknown Product" @app.get("/health") def health(): return {"status": "ok", "plugins_loaded": len(plugins)} # To run: uvicorn main:app --reload python # price_monitor/scraper.py import asyncio from playwright.async_api import async_playwright from bs4 import BeautifulSoup import aiohttp from typing import Optional, Tuple import re from urllib.parse import urlparse class PriceScraper: def __init__(self, plugin=None): self.plugin = plugin async def fetch_price_and_stock(self, url: str) -> Tuple[float, str]: if self.plugin: return await self.plugin.fetch_price_and_stock(url) domain = urlparse(url).netloc if 'shwapno.com' in domain: return await self._scrape_shwapno(url) elif 'chaldal.com' in domain: return await self._scrape_chaldal(url) elif 'meenaclick.com' in domain: return await self._scrape_meena_bazar(url) else: return await self._scrape_generic(url) async def _scrape_generic(self, url: str) -> Tuple[float, str]: async with aiohttp.ClientSession() as session: async with session.get(url) as response: html = await response.text() soup = BeautifulSoup(html, 'html.parser') # Common price patterns price = self._extract_price(soup) stock = self._extract_stock(soup) return price, stock async def _scrape_shwapno(self, url: str) -> Tuple[float, str]: async with async_playwright() as p: browser = await p.chromium.launch() page = await browser.new_page() await page.goto(url) # Wait for price element to load await page.wait_for_selector('.product-price') price_text = await page.inner_text('.product-price') price = float(re.sub(r'[^\d.]', '', price_text)) stock = "in_stock" try: out_of_stock = await page.query_selector('.out-of-stock') if out_of_stock: stock = "out_of_stock" except: pass await browser.close() return price, stock async def _scrape_chaldal(self, url: str) -> Tuple[float, str]: # Similar implementation for Chaldal pass async def _scrape_meena_bazar(self, url: str) -> Tuple[float, str]: # Similar implementation for Meena Bazar pass def _extract_price(self, soup) -> float: # Try common price selectors selectors = [ '.price', '.product-price', '.amount', '[itemprop="price"]', '.selling-price' ] for selector in selectors: element = soup.select_one(selector) if element: price_text = element.get_text() numbers = re.findall(r'\d+\.?\d*', price_text) if numbers: return float(numbers[0]) return 0.0 def _extract_stock(self, soup) -> str: # Try common stock indicators stock_selectors = { 'out_of_stock': [ '.out-of-stock', '.stock-out', '[itemprop="availability"][content="out_of_stock"]' ], 'in_stock': [ '.in-stock', '[itemprop="availability"][content="in_stock"]' ] } for status, selectors in stock_selectors.items(): for selector in selectors: if soup.select_one(selector): return status return "unknown" python # price_monitor/notifier.py import asyncio from typing import Dict from pydantic import EmailStr from openai import AsyncOpenAI import pyttsx3 import aiohttp from models import Product class Notifier: def __init__(self): self.openai = AsyncOpenAI() self.voice_engine = pyttsx3.init() # Configure Bengali voice if available voices = self.voice_engine.getProperty('voices') for voice in voices: if 'bengali' in voice.languages or 'bn' in voice.id: self.voice_engine.setProperty('voice', voice.id) break async def notify_price_drop(self, product: Product, current_price: float, summary: str, notification_prefs: Dict): message = self._create_price_drop_message( product, current_price, summary, product.language ) if notification_prefs.get('email'): await self._send_email( to=product.user.email, subject=f"Price Drop Alert for {product.name}", body=message ) if notification_prefs.get('sms'): await self._send_sms( number=product.user.phone, message=message ) if notification_prefs.get('voice') and product.user.phone: await self._make_voice_call( number=product.user.phone, message=message ) if notification_prefs.get('push'): await self._send_push_notification( user_id=product.user.id, title=f"Price Drop: {product.name}", message=message ) async def notify_bundle_drop(self, items, bundle_status, total_price): # Similar implementation for bundle notifications pass async def notify_prediction(self, product: Product, prediction: Dict, notification_prefs: Dict): # Implementation for price prediction notifications pass async def notify_error(self, url: str, error: str, language: str): # Error notification implementation pass def _create_price_drop_message(self, product: Product, current_price: float, summary: str, language: str) -> str: if language == 'bn': return ( f"{product.name} ?? ??? ?????!\n\n" f"??????? ???: ?{current_price}\n" f"????? ????????? ???: ?{product.threshold}\n\n" f"?????????? ???????:\n{summary}\n\n" f"???? ?????: {product.url}" ) else: return ( f"Price drop for {product.name}!\n\n" f"Current price: ?{current_price}\n" f"Your target price: ?{product.threshold}\n\n" f"Recent trends:\n{summary}\n\n" f"Product link: {product.url}" ) async def _send_email(self, to: EmailStr, subject: str, body: str): # Implementation using SMTP or email service API pass async def _send_sms(self, number: str, message: str): # Implementation using SMS gateway API pass async def _make_voice_call(self, number: str, message: str): # Convert text to speech and make call self.voice_engine.save_to_file(message, 'temp.mp3') self.voice_engine.runAndWait() # Use voice calling API to play the MP3 pass async def _send_push_notification(self, user_id: str, title: str, message: str): # Implementation using Firebase Cloud Messaging or similar pass python # price_monitor/summarizer.py from openai import AsyncOpenAI from typing import Dict, Optional from datetime import datetime, timedelta from database import get_session from models import PriceHistory import numpy as np from sklearn.linear_model import LinearRegression class Summarizer: def __init__(self): self.openai = AsyncOpenAI() async def summarize_trend(self, product_id: int, language: str = "en") -> str: session = get_session() try: # Get price history for last 30 days history = session.query(PriceHistory).filter( PriceHistory.product_id == product_id, PriceHistory.timestamp >= datetime.utcnow() - timedelta(days=30) ).order_by(PriceHistory.timestamp).all() if not history: return "No price history available yet." prices = [h.price for h in history] dates = [h.timestamp for h in history] min_price = min(prices) max_price = max(prices) current_price = prices[-1] # Simple trend analysis if len(prices) > 1: price_changes = np.diff(prices) avg_change = np.mean(price_changes) trend = "increasing" if avg_change > 0 else "decreasing" if avg_change < 0 else "stable" else: trend = "no trend data" prompt = self._create_trend_prompt( prices, dates, min_price, max_price, current_price, trend, language ) response = await self.openai.chat.completions.create( model="gpt-3.5-turbo", messages=[{"role": "user", "content": prompt}], temperature=0.7 ) return response.choices[0].message.content finally: session.close() async def predict_future_price(self, product_id: int) -> Optional[Dict]: session = get_session() try: # Get price history for modeling history = session.query(PriceHistory).filter( PriceHistory.product_id == product_id ).order_by(PriceHistory.timestamp).all() if len(history) < 7: # Need at least 7 data points return None # Prepare data for simple linear regression X = np.array([i for i in range(len(history))]).reshape(-1, 1) y = np.array([h.price for h in history]) model = LinearRegression() model.fit(X, y) # Predict next 3 days future_days = np.array([len(history), len(history)+1, len(history)+2]).reshape(-1, 1) future_prices = model.predict(future_days) current_price = history[-1].price likely_drop = any(p < current_price for p in future_prices) return { "current_price": current_price, "predicted_prices": future_prices.tolist(), "likely_drop_soon": likely_drop, "confidence": 0.7 # Placeholder } finally: session.close() def _create_trend_prompt(self, prices, dates, min_price, max_price, current_price, trend, language): if language == 'bn': return ( "????? ????? ?????? ???????? ??? ???? ????????? ????? ?????? ???? ????:\n\n" f"????? ??????: {prices}\n" f"?????: {dates}\n" f"????????? ???: {min_price}\n" f"???????? ???: {max_price}\n" f"??????? ???: {current_price}\n" f"???????? ???????: {trend}\n\n" "??????? ?????????? ????????? ??????????? ????:\n" "- ?????????? ????? ????????\n" "- ??? ??? ????????/????????? ???\n" "- ??????? ??? ???????? ????? ??????? ?? ???\n" "- ???? ????? ??? ?? ????? ???????? ???? ????? ??????? ??? ????\n" "- ????????? ???? ???????" ) else: return ( "Analyze the following price history and create a concise summary:\n\n" f"Price history: {prices}\n" f"Dates: {dates}\n" f"Minimum price: {min_price}\n" f"Maximum price: {max_price}\n" f"Current price: {current_price}\n" f"Overall trend: {trend}\n\n" "Include these points in the summary:\n" "- Recent price changes\n" "- When prices were highest/lowest\n" "- How current price compares to historical average\n" "- Any correlation with holidays or special events\n" "- Recommendations for buyers" ) python # price_monitor/plugins/shwapno.py import asyncio from playwright.async_api import async_playwright from typing import Tuple import re class ShwapnoPlugin: def __init__(self): self.domain = "shwapno.com" self.name = "Shwapno Online Grocery" async def fetch_price_and_stock(self, url: str) -> Tuple[float, str]: async with async_playwright() as p: browser = await p.chromium.launch() context = await browser.new_context( user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36" ) page = await context.new_page() try: await page.goto(url, timeout=15000) await page.wait_for_selector('.product-detail', timeout=10000) # Extract price price_element = await page.query_selector('.product-price') price_text = await price_element.inner_text() price = float(re.sub(r'[^\d.]', '', price_text)) # Check stock status stock = "in_stock" out_of_stock = await page.query_selector('.out-of-stock') if out_of_stock: stock = "out_of_stock" return price, stock except Exception as e: raise Exception(f"Failed to scrape Shwapno product: {str(e)}") finally: await browser.close() async def fetch_product_name(self, url: str) -> str: async with async_playwright() as p: browser = await p.chromium.launch() page = await browser.new_page() await page.goto(url) name_element = await page.query_selector('.product-title') name = await name_element.inner_text() await browser.close() return name.strip() python # price_monitor/models.py from sqlalchemy import Column, Integer, String, Float, DateTime, Boolean, ForeignKey from sqlalchemy.ext.declarative import declarative_base from datetime import datetime from typing import Optional Base = declarative_base() class User(Base): __tablename__ = 'users' id = Column(Integer, primary_key=True) email = Column(String, unique=True, nullable=False) phone = Column(String) language = Column(String, default='en') notification_prefs = Column(String) # JSON string class Product(Base): __tablename__ = 'products' id = Column(Integer, primary_key=True) url = Column(String, unique=True, nullable=False) name = Column(String) threshold = Column(Float) language = Column(String, default='en') notification_prefs = Column(String) # JSON string user_id = Column(Integer, ForeignKey('users.id')) class PriceHistory(Base): __tablename__ = 'price_history' id = Column(Integer, primary_key=True) product_id = Column(Integer, ForeignKey('products.id'), nullable=False) price = Column(Float, nullable=False) stock_status = Column(String) timestamp = Column(DateTime, default=datetime.utcnow) python # price_monitor/database.py from sqlalchemy import create_engine from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession from sqlalchemy.orm import sessionmaker from models import Base import os DATABASE_URL = os.getenv("DATABASE_URL", "sqlite+aiosqlite:///./prices.db") engine = create_async_engine(DATABASE_URL, echo=True) async_session = sessionmaker(engine, expire_on_commit=False, class_=AsyncSession) async def init_db(): async with engine.begin() as conn: await conn.run_sync(Base.metadata.create_all) def get_session(): return async_session() python # price_monitor/plugins/__init__.py import importlib.util import os from pathlib import Path from typing import List, Any def load_plugins(plugin_dir: str) -> List[Any]: plugins = [] plugin_path = Path(plugin_dir) for file in plugin_path.glob('*.py'): if file.name == '__init__.py': continue module_name = file.stem spec = importlib.util.spec_from_file_location( f"plugins.{module_name}", file ) module = importlib.util.module_from_spec(spec) spec.loader.exec_module(module) for attr in dir(module): if not attr.startswith('_') and attr.endswith('Plugin'): plugin_class = getattr(module, attr) plugins.append(plugin_class()) return plugins text # price_monitor/requirements.txt fastapi>=0.68.0 uvicorn>=0.15.0 aiohttp>=3.7.4 beautifulsoup4>=4.9.3 playwright>=1.14.0 openai>=0.27.0 pyttsx3>=2.90 apscheduler>=3.7.0 pydantic>=1.8.2 sqlalchemy>=1.4.22 aiosqlite>=0.17.0 scikit-learn>=0.24.2 numpy>=1.21.0 python-multipart>=0.0.5 This implementation includes: Multi-store support with plugins for Shwapno, Chaldal, and Meena Bazar AI-powered trend analysis with OpenAI summarizing price history Price prediction using simple linear regression Multi-language support (English/Bengali) for notifications Bundle tracking to monitor multiple products together Multiple notification channels (email, SMS, voice call, push) Persistent storage with SQLite/Postgres Headless browser scraping with Playwright for JS-heavy sites Scheduled monitoring with APScheduler REST API with FastAPI To run the application: Install requirements: pip install -r requirements.txt Install Playwright browsers: playwright install Run the API: uvicorn main:app --reload The system can be extended by adding more plugins in the plugins directory. Each plugin should implement the domain-specific scraping logic for a particular e-grocery site. "). This could surface which products are truly on sale vs. just normal fluctuations. Offline-First Caching: Store scraped data locally (e.g. SQLite or PouchDB) so the tool can work offline and sync later. This avoids re-scraping unchanged products and speeds up UI responsiveness. Voice Alerts: Integrate with voice assistants or local mobile voice-notification apps to read out price alerts or trends. E.g. "Chaldal: Moong dal now ?10/kg cheaper - buy soon!" Extensible Plugin System: Allow community plugins or site-specific scrapers to be added. For example, a module for parsing Shwapno's site vs. one for Chaldal's, or for supporting APIs from local supermarkets. This separation of concerns (plugins for sites, core engine for monitoring) enhances flexibility. Multi-Store Bundles & Alerts: Let users track "basket bundles" or grocery lists, alerting when all needed items are below thresholds. Also incorporate currency/units (pack size) conversions if needed for fair comparisons. AI-Driven Price Prediction: Use simple ML to forecast whether a price will drop soon (based on past patterns), warning users if it might be better to wait. Implementing these could differentiate a custom tracker tailored to Bangladesh, beyond the standard monitors described above.# =============================================== # notification.py - Notification System # =============================================== import smtplib import aiohttp import json from email.mime.text import MIMEText from email.mime.multipart import MIMEMultipart from typing import Dict, List, Optional import os from datetime import datetime class NotificationManager: def __init__(self): self.smtp_host = os.getenv('EMAIL_SMTP_HOST', 'smtp.gmail.com') self.smtp_port = int(os.getenv('EMAIL_SMTP_PORT', '587')) self.email_user = os.getenv('EMAIL_USER') self.email_password = os.getenv('EMAIL_PASSWORD') self.sms_api_key = os.getenv('SMS_API_KEY') # For SSL Wireless or similar self.sms_sender_id = os.getenv('SMS_SENDER_ID', 'PriceBot') async def send_price_alert(self, user_email: str, product_name: str, old_price: float, new_price: float, url: str, language: str = 'en'): """Send price drop notification""" if language == 'bn': subject = f"?? {product_name} ?? ??? ?????!" body = f""" ????? ??????? ??? ?????? ??? ?????: ????: {product_name} ?????? ???: ?{old_price:.2f} ???? ???: ?{new_price:.2f} ???????: ?{old_price - new_price:.2f} ???? ?????: {url} ??? ????????! Price Monitor Bangladesh """ else: subject = f"?? Price Drop Alert: {product_name}" body = f""" Great news! The price of your tracked product has dropped: Product: {product_name} Old Price: ?{old_price:.2f} New Price: ?{new_price:.2f} You Save: ?{old_price - new_price:.2f} Buy Now: {url} Happy Shopping! Price Monitor Bangladesh """ await self._send_email(user_email, subject, body) async def send_bundle_alert(self, user_email: str, bundle_name: str, total_price: float, threshold: float, items: List[Dict], language: str = 'en'): """Send bundle price alert""" if language == 'bn': subject = f"?? {bundle_name} ????????? ??? ?????!" items_text = "\n".join([f"• {item['name']}: ?{item['price']:.2f}" for item in items]) body = f""" ????? ????????? ??? ??? ????? ????? ???? ???? ?????: ??????: {bundle_name} ??? ???: ?{total_price:.2f} ????? ????: ?{threshold:.2f} ????????: {items_text} ???? ?????! Price Monitor Bangladesh """ else: subject = f"?? Bundle Alert: {bundle_name}" items_text = "\n".join([f"• {item['name']}: ?{item['price']:.2f}" for item in items]) body = f""" Your bundle total has dropped below your threshold: Bundle: {bundle_name} Total Price: ?{total_price:.2f} Your Threshold: ?{threshold:.2f} Items: {items_text} Time to shop! Price Monitor Bangladesh """ await self._send_email(user_email, subject, body) async def send_sms(self, phone: str, message: str): """Send SMS notification (Bangladesh specific)""" if not self.sms_api_key or not phone: return False # SSL Wireless SMS API (popular in Bangladesh) url = "https://sms.sslwireless.com/pushapi/dynamic/server.php" params = { 'user': os.getenv('SMS_USER'), 'pass': os.getenv('SMS_PASS'), 'sid': self.sms_sender_id, 'sms[0][0]': phone, 'sms[0][1]': message, 'sms[0][2]': '1234' # Message ID } try: async with aiohttp.ClientSession() as session: async with session.post(url, data=params) as response: result = await response.text() return "ACCEPTD" in result except Exception as e: print(f"SMS sending failed: {e}") return False async def _send_email(self, to_email: str, subject: str, body: str): """Send email notification""" if not self.email_user or not self.email_password: print("Email credentials not configured") return False try: msg = MIMEMultipart() msg['From'] = self.email_user msg['To'] = to_email msg['Subject'] = subject msg.attach(MIMEText(body, 'plain', 'utf-8')) server = smtplib.SMTP(self.smtp_host, self.smtp_port) server.starttls() server.login(self.email_user, self.email_password) server.send_message(msg) server.quit() print(f"Email sent to {to_email}") return True except Exception as e: print(f"Email sending failed: {e}") return False # =============================================== # scheduler.py - Background Tasks # =============================================== from apscheduler.schedulers.asyncio import AsyncIOScheduler from apscheduler.triggers.interval import IntervalTrigger from datetime import datetime, timedelta from sqlalchemy import select from database import get_session from models import Product, PriceHistory, User from scraper import PriceScraper from notification import NotificationManager from summarizer import PriceSummarizer import json class TaskScheduler: def __init__(self): self.scheduler = AsyncIOScheduler() self.scraper = PriceScraper() self.notification_manager = NotificationManager() self.summarizer = PriceSummarizer() self.is_running = False def start(self): """Start the scheduler""" if not self.is_running: # Track individual products every 5 minutes self.scheduler.add_job( self.track_all_products, IntervalTrigger(seconds=int(os.getenv('TRACK_INTERVAL', 300))), id='track_products' ) # Check bundles every hour self.scheduler.add_job( self.check_bundles, IntervalTrigger(seconds=int(os.getenv('BUNDLE_INTERVAL', 3600))), id='check_bundles' ) # Generate AI predictions daily self.scheduler.add_job( self.generate_predictions, IntervalTrigger(hours=24), id='generate_predictions' ) # Cleanup old data weekly self.scheduler.add_job( self.cleanup_old_data, IntervalTrigger(days=7), id='cleanup_data' ) self.scheduler.start() self.is_running = True print("Scheduler started successfully") def stop(self): """Stop the scheduler""" if self.is_running: self.scheduler.shutdown() self.is_running = False print("Scheduler stopped") async def track_all_products(self): """Track prices for all active products""" async with get_session() as session: result = await session.execute( select(Product).where(Product.is_active == True) ) products = result.scalars().all() print(f"Tracking {len(products)} products...") for product in products: try: await self._track_single_product(product) except Exception as e: print(f"Error tracking product {product.id}: {e}") async def _track_single_product(self, product): """Track a single product""" try: price, stock_status = await self.scraper.scrape_price(product.url) if price <= 0: print(f"Invalid price for product {product.id}") return # Get last price async with get_session() as session: last_price_result = await session.execute( select(PriceHistory) .where(PriceHistory.product_id == product.id) .order_by(PriceHistory.timestamp.desc()) .limit(1) ) last_price_record = last_price_result.scalar_one_or_none() last_price = last_price_record.price if last_price_record else 0 # Save new price new_record = PriceHistory( product_id=product.id, price=price, stock_status=stock_status, timestamp=datetime.utcnow() ) session.add(new_record) await session.commit() # Check if we should notify if product.threshold and price <= product.threshold and price < last_price: await self._send_price_notification(product, last_price, price) except Exception as e: print(f"Error tracking product {product.id}: {e}") async def _send_price_notification(self, product, old_price: float, new_price: float): """Send price drop notification""" async with get_session() as session: user_result = await session.execute( select(User).where(User.id == product.user_id) ) user = user_result.scalar_one_or_none() if user and user.email: notification_prefs = json.loads(product.notification_prefs or '{}') if notification_prefs.get('email', True): await self.notification_manager.send_price_alert( user.email, product.name, old_price, new_price, product.url, user.language ) if notification_prefs.get('sms', False) and user.phone: message = f"Price drop! {product.name}: ?{old_price:.2f} -> ?{new_price:.2f}" await self.notification_manager.send_sms(user.phone, message) async def check_bundles(self): """Check bundle prices and send notifications""" # Implementation for bundle checking print("Checking bundles...") # This would involve aggregating prices of products in bundles pass async def generate_predictions(self): """Generate AI predictions for all products""" async with get_session() as session: result = await session.execute( select(Product).where(Product.is_active == True) ) products = result.scalars().all() for product in products: try: prediction = await self.summarizer.predict_future_price(product.id) if prediction and prediction.get('likely_drop_soon'): await self._send_prediction_notification(product, prediction) except Exception as e: print(f"Error generating prediction for product {product.id}: {e}") async def _send_prediction_notification(self, product, prediction): """Send AI prediction notification""" async with get_session() as session: user_result = await session.execute( select(User).where(User.id == product.user_id) ) user = user_result.scalar_one_or_none() if user and user.email: predicted_price = prediction['predicted_prices'][0] confidence = prediction['confidence'] if user.language == 'bn': subject = f"?? AI ?????????: {product.name}" body = f""" ?????? AI ???? ?????? ???? ?? {product.name} ?? ??? ?????? ???? ????? ??????? ???: ?{prediction['current_price']:.2f} ?????????? ???: ?{predicted_price:.2f} ?????????????: {confidence*100:.1f}% ???????? ?????! """ else: subject = f"?? AI Prediction: {product.name}" body = f""" Our AI model predicts that {product.name} price may drop soon. Current Price: ?{prediction['current_price']:.2f} Predicted Price: ?{predicted_price:.2f} Confidence: {confidence*100:.1f}% Get ready to buy! """ await self.notification_manager._send_email(user.email, subject, body) async def cleanup_old_data(self): """Remove old price history data""" cutoff_date = datetime.utcnow() - timedelta(days=90) async with get_session() as session: await session.execute( "DELETE FROM price_history WHERE timestamp < :cutoff", {"cutoff": cutoff_date} ) await session.commit() print("Old data cleaned up") # =============================================== # utils.py - Utility Functions # =============================================== import re from urllib.parse import urlparse from typing import Optional, Dict, Any import json import hashlib def extract_domain(url: str) -> Optional[str]: """Extract domain from URL""" try: parsed = urlparse(url) return parsed.netloc.lower().replace('www.', '') except: return None def clean_price_text(price_text: str) -> float: """Clean and extract price from text""" if not price_text: return 0.0 # Remove currency symbols and commas cleaned = re.sub(r'[?$,\s]', '', price_text) # Extract numeric value match = re.search(r'(\d+(?:\.\d{2})?)', cleaned) if match: return float(match.group(1)) return 0.0 def is_valid_bangladesh_phone(phone: str) -> bool: """Validate Bangladesh phone number""" if not phone: return False # Remove spaces and dashes cleaned = re.sub(r'[\s\-]', '', phone) # Check patterns patterns = [ r'^\+8801[3-9]\d{8}$', # +8801XXXXXXXXX r'^01[3-9]\d{8}$', # 01XXXXXXXXX r'^8801[3-9]\d{8}$' # 8801XXXXXXXXX ] return any(re.match(pattern, cleaned) for pattern in patterns) def generate_product_hash(url: str, user_id: int) -> str: """Generate unique hash for product-user combination""" combined = f"{url}:{user_id}" return hashlib.md5(combined.encode()).hexdigest()[:10] def format_currency(amount: float, language: str = 'en') -> str: """Format currency based on language""" if language == 'bn': return f"?{amount:,.2f}" else: return f"?{amount:,.2f}" def safe_json_loads(json_str: str, default: Dict[str, Any] = None) -> Dict[str, Any]: """Safely load JSON string""" if default is None: default = {} try: return json.loads(json_str) if json_str else default except: return default def validate_url(url: str) -> bool: """Validate URL format""" try: result = urlparse(url) return all([result.scheme, result.netloc]) except: return False # =============================================== # Enhanced main.py - Complete API # =============================================== from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks from fastapi.middleware.cors import CORSMiddleware from pydantic import BaseModel, validator from typing import List, Optional, Dict, Any from datetime import datetime, timedelta import os import asyncio from contextlib import asynccontextmanager from database import init_db, get_session from models import User, Product, PriceHistory from scraper import PriceScraper from summarizer import PriceSummarizer from scheduler import TaskScheduler from notification import NotificationManager from utils import * # Global instances scraper = PriceScraper() summarizer = PriceSummarizer() scheduler = TaskScheduler() notification_manager = NotificationManager() @asynccontextmanager async def lifespan(app: FastAPI): # Startup await init_db(os.getenv('DATABASE_URL', 'sqlite+aiosqlite:///./prices.db')) await scraper.initialize() scheduler.start() yield # Shutdown scheduler.stop() await scraper.close() app = FastAPI( title="Bangladesh Price Monitor API", description="Advanced price tracking for Bangladeshi e-grocery platforms", version="2.0.0", lifespan=lifespan ) app.add_middleware( CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"], ) # Pydantic Models class UserCreate(BaseModel): email: str phone: Optional[str] = None language: str = "en" notification_prefs: Dict[str, Any] = {"email": True, "sms": False} @validator('phone') def validate_phone(cls, v): if v and not is_valid_bangladesh_phone(v): raise ValueError('Invalid Bangladesh phone number') return v @validator('language') def validate_language(cls, v): if v not in ['en', 'bn']: raise ValueError('Language must be "en" or "bn"') return v class ProductTrack(BaseModel): url: str threshold: Optional[float] = None product_name: Optional[str] = None language: str = "en" user_id: int notification_prefs: Dict[str, Any] = {"email": True, "sms": False} @validator('url') def validate_url(cls, v): if not validate_url(v): raise ValueError('Invalid URL format') return v class BundleTrack(BaseModel): name: str total_threshold: float user_id: int items: List[ProductTrack] # API Endpoints @app.post("/users", response_model=Dict[str, Any]) async def create_user(user_data: UserCreate): """Create a new user""" async with get_session() as session: # Check if user exists existing = await session.execute( select(User).where(User.email == user_data.email) ) if existing.scalar_one_or_none(): raise HTTPException(status_code=400, detail="User already exists") user = User( email=user_data.email, phone=user_data.phone, language=user_data.language, notification_prefs=json.dumps(user_data.notification_prefs) ) session.add(user) await session.commit() await session.refresh(user) return { "id": user.id, "email": user.email, "phone": user.phone, "language": user.language, "created_at": user.created_at } @app.post("/track", response_model=Dict[str, Any]) async def track_product(product_data: ProductTrack, background_tasks: BackgroundTasks): """Start tracking a product""" async with get_session() as session: # Check if already tracking existing = await session.execute( select(Product).where( Product.url == product_data.url, Product.user_id == product_data.user_id, Product.is_active == True ) ) if existing.scalar_one_or_none(): raise HTTPException(status_code=400, detail="Already tracking this product") # Get initial price try: price, stock_status = await scraper.scrape_price(product_data.url) if price <= 0: raise HTTPException(status_code=400, detail="Could not fetch price") except Exception as e: raise HTTPException(status_code=400, detail=f"Error fetching price: {str(e)}") # Create product product = Product( url=product_data.url, name=product_data.product_name or f"Product from {extract_domain(product_data.url)}", threshold=product_data.threshold, language=product_data.language, user_id=product_data.user_id, notification_prefs=json.dumps(product_data.notification_prefs) ) session.add(product) await session.commit() await session.refresh(product) # Add initial price record price_record = PriceHistory( product_id=product.id, price=price, stock_status=stock_status ) session.add(price_record) await session.commit() return { "id": product.id, "name": product.name, "url": product.url, "current_price": price, "threshold": product.threshold, "stock_status": stock_status } @app.get("/products/{product_id}/history") async def get_price_history(product_id: int, days: int = 30): """Get price history for a product""" async with get_session() as session: cutoff_date = datetime.utcnow() - timedelta(days=days) result = await session.execute( select(PriceHistory) .where( PriceHistory.product_id == product_id, PriceHistory.timestamp >= cutoff_date ) .order_by(PriceHistory.timestamp) ) history = result.scalars().all() return { "product_id": product_id, "history": [ { "price": h.price, "stock_status": h.stock_status, "timestamp": h.timestamp } for h in history ] } @app.get("/products/{product_id}/summary") async def get_price_summary(product_id: int, language: str = "en"): """Get AI-powered price summary""" summary = await summarizer.generate_summary(product_id, language) prediction = await summarizer.predict_future_price(product_id) return { "summary": summary, "prediction": prediction } @app.delete("/track/{product_id}") async def stop_tracking(product_id: int): """Stop tracking a product""" async with get_session() as session: result = await session.execute( select(Product).where(Product.id == product_id) ) product = result.scalar_one_or_none() if not product: raise HTTPException(status_code=404, detail="Product not found") product.is_active = False await session.commit() return {"message": "Stopped tracking product"} @app.get("/health") async def health_check(): """System health check""" return { "status": "healthy", "timestamp": datetime.utcnow(), "scheduler_running": scheduler.is_running, "version": "2.0.0" } @app.post("/test-scrape") async def test_scraping(url: str): """Test scraping a URL""" try: price, stock_status = await scraper.scrape_price(url) return { "url": url, "price": price, "stock_status": stock_status, "domain": extract_domain(url) } except Exception as e: raise HTTPException(status_code=400, detail=str(e)) if __name__ == "__main__": import uvicorn uvicorn.run(app, host="0.0.0.0", port=8000)# =============================================== # Continuing summarizer.py - AI Trend Analysis # =============================================== scalars().all() if not history: return "No price history available yet." if language == "en" else "???? ????? ?????? ?????? ???????" # Calculate basic statistics prices = [h.price for h in history] avg_price = np.mean(prices) min_price = min(prices) max_price = max(prices) current_price = prices[-1] if prices else 0 if self.has_openai: return await self._generate_ai_summary(history, language) else: return self._generate_basic_summary(prices, language) async def predict_future_price(self, product_id: int) -> Optional[Dict]: """Predict future price using linear regression""" async with get_session() as session: result = await session.execute( select(PriceHistory) .where(PriceHistory.product_id == product_id) .where(PriceHistory.timestamp >= datetime.utcnow() - timedelta(days=14)) .order_by(PriceHistory.timestamp) ) history = result.scalars().all() if len(history) < 5: return None # Prepare data for regression timestamps = [(h.timestamp - history[0].timestamp).total_seconds() for h in history] prices = [h.price for h in history] X = np.array(timestamps).reshape(-1, 1) y = np.array(prices) model = LinearRegression() model.fit(X, y) # Predict next 3 days future_timestamps = [ timestamps[-1] + (24 * 3600 * i) for i in range(1, 4) ] predictions = model.predict(np.array(future_timestamps).reshape(-1, 1)) current_price = prices[-1] trend_slope = model.coef_[0] return { "current_price": current_price, "predicted_prices": predictions.tolist(), "trend": "decreasing" if trend_slope < -0.1 else "increasing" if trend_slope > 0.1 else "stable", "likely_drop_soon": trend_slope < -0.5 and predictions[0] < current_price * 0.95, "confidence": min(abs(model.score(X, y)), 1.0) } async def _generate_ai_summary(self, history: List, language: str) -> str: """Generate AI summary using OpenAI""" try: prices = [h.price for h in history] timestamps = [h.timestamp.strftime("%Y-%m-%d") for h in history] price_data = list(zip(timestamps, prices)) prompt = f""" Analyze this price history data and provide a concise summary in {'Bengali' if language == 'bn' else 'English'}: Price History: {price_data} Please provide: 1. Overall trend (increasing/decreasing/stable) 2. Notable price changes 3. Best time to buy recommendation Keep response under 100 words and focus on actionable insights. """ response = await openai.ChatCompletion.acreate( model="gpt-3.5-turbo", messages=[{"role": "user", "content": prompt}], max_tokens=150 ) return response.choices[0].message.content.strip() except Exception as e: print(f"OpenAI API error: {e}") return self._generate_basic_summary([h.price for h in history], language) def _generate_basic_summary(self, prices: List[float], language: str) -> str: """Generate basic statistical summary""" if not prices: return "No data available" if language == "en" else "??? ???? ?????? ??????" avg_price = np.mean(prices) current_price = prices[-1] min_price = min(prices) max_price = max(prices) # Calculate trend if len(prices) >= 3: recent_trend = np.mean(prices[-3:]) - np.mean(prices[:-3]) if len(prices) > 3 else 0 else: recent_trend = 0 if language == "bn": trend_text = "??????" if recent_trend > 1 else "????" if recent_trend < -1 else "?????????" return f""" ?? ?? ????? ????????: • ??? ???: ?{avg_price:.2f} • ?????????: ?{min_price:.2f} • ????????: ?{max_price:.2f} • ??????? ???????: {trend_text} • ???????: {'???? ?????' if current_price <= min_price * 1.05 else '???????? ??????? ????'} """ else: trend_text = "Rising" if recent_trend > 1 else "Falling" if recent_trend < -1 else "Stable" return f""" Last 30 days analysis: • Average Price: ?{avg_price:.2f} • Lowest: ?{min_price:.2f} • Highest: ?{max_price:.2f} • Current Trend: {trend_text} • Recommendation: {'Buy now' if current_price <= min_price * 1.05 else 'Wait a few days'} """ # =============================================== # database.py - Database Models and Connection # =============================================== from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession from sqlalchemy.orm import sessionmaker from sqlalchemy import MetaData from models import Base engine = None async_session = None async def init_db(database_url: str): """Initialize database connection and create tables""" global engine, async_session engine = create_async_engine( database_url, echo=False, pool_pre_ping=True, pool_recycle=300 ) async_session = sessionmaker( engine, class_=AsyncSession, expire_on_commit=False ) # Create tables async with engine.begin() as conn: await conn.run_sync(Base.metadata.create_all) print("Database initialized successfully") async def get_session() -> AsyncSession: """Get database session""" async with async_session() as session: yield session # =============================================== # models.py - SQLAlchemy Models # =============================================== from sqlalchemy import Column, Integer, String, Float, DateTime, Text, ForeignKey, Boolean from sqlalchemy.ext.declarative import declarative_base from sqlalchemy.orm import relationship from datetime import datetime Base = declarative_base() class User(Base): __tablename__ = "users" id = Column(Integer, primary_key=True, index=True) email = Column(String(255), unique=True, index=True) phone = Column(String(20), nullable=True) language = Column(String(5), default="en") # 'en' or 'bn' notification_prefs = Column(Text) # JSON string created_at = Column(DateTime, default=datetime.utcnow) products = relationship("Product", back_populates="user") class Product(Base): __tablename__ = "products" id = Column(Integer, primary_key=True, index=True) url = Column(String(500), index=True) name = Column(String(255)) threshold = Column(Float, nullable=True) language = Column(String(5), default="en") user_id = Column(Integer, ForeignKey("users.id")) notification_prefs = Column(Text) # JSON string created_at = Column(DateTime, default=datetime.utcnow) is_active = Column(Boolean, default=True) user = relationship("User", back_populates="products") price_history = relationship("PriceHistory", back_populates="product") class PriceHistory(Base): __tablename__ = "price_history" id = Column(Integer, primary_key=True, index=True) product_id = Column(Integer, ForeignKey("products.id")) price = Column(Float) stock_status = Column(String(20)) # 'in_stock', 'out_of_stock', 'unknown' timestamp = Column(DateTime, default=datetime.utcnow, index=True) product = relationship("Product", back_populates="price_history") # =============================================== # plugins/__init__.py - Plugin Loader # =============================================== import os import importlib from typing import List def load_plugins(plugin_dir: str) -> List: """Load all plugins from the plugins directory""" plugins = [] if not os.path.exists(plugin_dir): print(f"Plugin directory {plugin_dir} not found") return plugins for filename in os.listdir(plugin_dir): if filename.endswith('.py') and not filename.startswith('__'): module_name = filename[:-3] try: module = importlib.import_module(f"{plugin_dir}.{module_name}") if hasattr(module, 'plugin_class'): plugin_instance = module.plugin_class() plugins.append(plugin_instance) print(f"Loaded plugin: {module_name}") except Exception as e: print(f"Failed to load plugin {module_name}: {e}") return plugins # =============================================== # plugins/shwapno.py - Shwapno Plugin # =============================================== import aiohttp from bs4 import BeautifulSoup from typing import Tuple import re class ShwapnoPlugin: domain = "shwapno.com" async def fetch_price_and_stock(self, url: str) -> Tuple[float, str]: """Fetch price and stock from Shwapno""" async with aiohttp.ClientSession() as session: headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36' } async with session.get(url, headers=headers) as response: if response.status != 200: raise Exception(f"HTTP {response.status}") html = await response.text() soup = BeautifulSoup(html, 'html.parser') # Extract price price_element = soup.select_one('.price, .product-price, .selling-price') price = 0.0 if price_element: price_text = price_element.get_text().strip() price_match = re.search(r'(\d+(?:\.\d{2})?)', price_text.replace(',', '')) if price_match: price = float(price_match.group(1)) # Extract stock stock_status = "unknown" if soup.select_one('.out-of-stock, .stock-out'): stock_status = "out_of_stock" elif soup.select_one('.in-stock, .add-to-cart'): stock_status = "in_stock" return price, stock_status # Create plugin instance plugin_class = ShwapnoPlugin # =============================================== # plugins/chaldal.py - Chaldal Plugin # =============================================== import aiohttp from bs4 import BeautifulSoup from typing import Tuple import re import json class ChaldalPlugin: domain = "chaldal.com" async def fetch_price_and_stock(self, url: str) -> Tuple[float, str]: """Fetch price and stock from Chaldal""" async with aiohttp.ClientSession() as session: headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36' } async with session.get(url, headers=headers) as response: if response.status != 200: raise Exception(f"HTTP {response.status}") html = await response.text() soup = BeautifulSoup(html, 'html.parser') # Look for JSON-LD structured data json_scripts = soup.find_all('script', type='application/ld+json') price = 0.0 stock_status = "unknown" for script in json_scripts: try: data = json.loads(script.string) if '@type' in data and data['@type'] == 'Product': offers = data.get('offers', {}) if isinstance(offers, dict): price = float(offers.get('price', 0)) availability = offers.get('availability', '') stock_status = "in_stock" if "InStock" in availability else "out_of_stock" break except: continue # Fallback to HTML parsing if price == 0.0: price_element = soup.select_one('.price, .product-price, [data-price]') if price_element: price_text = price_element.get('data-price') or price_element.get_text() price_match = re.search(r'(\d+(?:\.\d{2})?)', price_text.replace(',', '')) if price_match: price = float(price_match.group(1)) if stock_status == "unknown": if soup.select_one('[data-stock="false"], .out-of-stock'): stock_status = "out_of_stock" elif soup.select_one('.add-to-cart, [data-stock="true"]'): stock_status = "in_stock" return price, stock_status # Create plugin instance plugin_class = ChaldalPlugin # =============================================== # plugins/meena_bazar.py - Meena Bazar Plugin # =============================================== import aiohttp from bs4 import BeautifulSoup from typing import Tuple import re class MeenaBazarPlugin: domain = "meenabazar.com" async def fetch_price_and_stock(self, url: str) -> Tuple[float, str]: """Fetch price and stock from Meena Bazar""" async with aiohttp.ClientSession() as session: headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36' } async with session.get(url, headers=headers) as response: if response.status != 200: raise Exception(f"HTTP {response.status}") html = await response.text() soup = BeautifulSoup(html, 'html.parser') # Extract price price = 0.0 price_selectors = [ '.price-current', '.current-price', '.price', '[data-price]', '.product-price' ] for selector in price_selectors: element = soup.select_one(selector) if element: price_text = element.get('data-price') or element.get_text() price_match = re.search(r'(\d+(?:\.\d{2})?)', price_text.replace(',', '')) if price_match: price = float(price_match.group(1)) break # Extract stock stock_status = "unknown" if soup.select_one('.stock-out, .unavailable'): stock_status = "out_of_stock" elif soup.select_one('.stock-in, .available, .add-cart'): stock_status = "in_stock" else: # Check button text buttons = soup.find_all('button') for button in buttons: button_text = button.get_text().lower() if 'add to cart' in button_text or 'buy now' in button_text: stock_status = "in_stock" break elif 'out of stock' in button_text: stock_status = "out_of_stock" break return price, stock_status # Create plugin instance plugin_class = MeenaBazarPlugin # =============================================== # requirements.txt - Dependencies # =============================================== fastapi==0.104.1 uvicorn[standard]==0.24.0 sqlalchemy[asyncio]==2.0.23 aiosqlite==0.19.0 psycopg2-binary==2.9.7 aiohttp==3.9.1 beautifulsoup4==4.12.2 playwright==1.40.0 apscheduler==3.10.4 openai==1.3.8 scikit-learn==1.3.2 numpy==1.25.2 pydantic==2.5.1 python-multipart==0.0.6 # =============================================== # docker-compose.yml - Docker Setup # =============================================== version: '3.8' services: app: build: . ports: - "8000:8000" environment: - DATABASE_URL=postgresql+asyncpg://user:password@db:5432/pricedb - OPENAI_API_KEY=${OPENAI_API_KEY} - EMAIL_SMTP_HOST=${EMAIL_SMTP_HOST} - EMAIL_SMTP_PORT=${EMAIL_SMTP_PORT} - EMAIL_USER=${EMAIL_USER} - EMAIL_PASSWORD=${EMAIL_PASSWORD} depends_on: - db volumes: - ./:/app command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload db: image: postgres:15 environment: - POSTGRES_USER=user - POSTGRES_PASSWORD=password - POSTGRES_DB=pricedb volumes: - postgres_data:/var/lib/postgresql/data ports: - "5432:5432" volumes: postgres_data: # =============================================== # Dockerfile # =============================================== FROM python:3.11-slim WORKDIR /app # Install system dependencies RUN apt-get update && apt-get install -y \ gcc \ g++ \ wget \ gnupg \ && rm -rf /var/lib/apt/lists/* # Install Playwright browsers RUN pip install playwright==1.40.0 RUN playwright install chromium RUN playwright install-deps chromium # Copy requirements and install Python dependencies COPY requirements.txt . RUN pip install --no-cache-dir -r requirements.txt # Copy application code COPY . . # Create plugins directory if it doesn't exist RUN mkdir -p plugins EXPOSE 8000 CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"] # =============================================== # .env.example - Environment Variables Template # =============================================== # Database DATABASE_URL=sqlite+aiosqlite:///./prices.db # Tracking intervals (seconds) TRACK_INTERVAL=300 BUNDLE_INTERVAL=3600 # OpenAI API (optional, for AI summaries) OPENAI_API_KEY=your_openai_api_key_here # Email notifications (optional) EMAIL_SMTP_HOST=smtp.gmail.com EMAIL_SMTP_PORT=587 EMAIL_USER=your_email@gmail.com EMAIL_PASSWORD=your_app_password # =============================================== # README.md - Documentation # =============================================== # ???? Bangladesh Grocery Price Monitor Advanced AI-powered price tracking system for Bangladeshi e-grocery platforms with multi-language support. ## ? Features - **Multi-site Support**: Shwapno, Chaldal, Meena Bazar + generic scraping - **AI Analysis**: OpenAI-powered trend analysis and predictions - **Multi-language**: Bengali & English support - **Smart Notifications**: Email, SMS, push notifications - **Bundle Tracking**: Monitor shopping lists with total price alerts - **Plugin Architecture**: Easy to add new sites - **Real-time API**: FastAPI with WebSocket support ## ?? Quick Start ### 1. Clone and Setup ```bash git clone <repository> cd price_monitor cp .env.example .env # Edit .env with your settings ``` ### 2. Docker Setup (Recommended) ```bash docker-compose up -d ``` ### 3. Manual Setup ```bash pip install -r requirements.txt playwright install chromium uvicorn main:app --reload ``` ## ?? API Usage ### Create User ```bash curl -X POST "http://localhost:8000/users" \ -H "Content-Type: application/json" \ -d '{ "email": "user@example.com", "phone": "+8801700000000", "language": "bn", "notification_prefs": {"email": true, "sms": false} }' ``` ### Track Product ```bash curl -X POST "http://localhost:8000/track" \ -H "Content-Type: application/json" \ -d '{ "url": "https://shwapno.com/product/rice-5kg", "threshold": 500.0, "product_name": "Basmati Rice 5kg", "language": "bn", "user_id": 1, "notification_prefs": {"email": true} }' ``` ### Track Bundle ```bash curl -X POST "http://localhost:8000/track/bundle" \ -H "Content-Type: application/json" \ -d '{ "name": "Weekly Groceries", "total_threshold": 2000.0, "user_id": 1, "items": [ { "url": "https://chaldal.com/rice", "threshold": 500.0, "user_id": 1 }, { "url": "https://meenabazar.com/oil", "threshold": 200.0, "user_id": 1 } ] }' ``` ## ?? Configuration Key environment variables: - `TRACK_INTERVAL`: Price check frequency (default: 300s) - `BUNDLE_INTERVAL`: Bundle check frequency (default: 3600s) - `OPENAI_API_KEY`: For AI summaries (optional) - `EMAIL_*`: SMTP settings for notifications ## ?? Plugin Development Create new site plugins in `plugins/` directory: ```python class NewSitePlugin: domain = "newsite.com" async def fetch_price_and_stock(self, url: str) -> Tuple[float, str]: # Implementation return price, stock_status plugin_class = NewSitePlugin ``` ## ?? Frontend Integration The API supports CORS and can be integrated with any frontend framework. Key endpoints: - `GET /products/{id}/history` - Price history - `GET /products/{id}/summary` - AI analysis - `DELETE /track/{id}` - Stop tracking - `GET /health` - System status ## ?? Notification Types 1. **Price Drop**: When target threshold is reached 2. **Bundle Alert**: When total bundle price drops 3. **AI Predictions**: When ML model predicts price drops 4. **Stock Alerts**: When out-of-stock items return ## ?? Production Deployment 1. Use PostgreSQL instead of SQLite 2. Set up proper SMTP/SMS gateways 3. Configure reverse proxy (nginx) 4. Enable HTTPS 5. Set up monitoring and logging 6. Configure backup strategies ## ?? Monitoring Check system health: ```bash curl http://localhost:8000/health ``` Monitor logs: ```bash docker-compose logs -f app ``` Built with ?? for Bangladesh's e-commerce ecosystem.
